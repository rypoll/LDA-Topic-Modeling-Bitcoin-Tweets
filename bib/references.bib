@inproceedings{autolabel,
  title={Automatic labelling of topic models},
  author={Lau, Jey Han and Grieser, Karl and Newman, David and Baldwin, Timothy},
  booktitle={Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies},
  pages={1536--1545},
  year={2011}
}


@inproceedings{lexandtm,
  title={Joint sentiment/topic model for sentiment analysis},
  author={Lin, Chenghua and He, Yulan},
  booktitle={Proceedings of the 18th ACM conference on Information and knowledge management},
  pages={375--384},
  year={2009}
}


@misc{rocket, title={rocket emoji}, url={https://emojipedia.org/rocket/#:~:text=Emoji%20Meaning,to%20Emoji%201.0%20in%202015.}, journal={Emojipedia}, year={2021}} 


@book{arimax2, place={Hoboken, NJ}, title={Time series analysis: Forecasting and control}, publisher={John Wiley &amp; Sons, Inc.}, author={P., Box George E and Jenkins, Gwilym M. and Reinsel, Gregory C. and Ljung, Greta M.}, year={2016}} 



@article{arimax1,
  title={Multivariate vehicular traffic flow prediction: evaluation of ARIMAX modeling},
  author={Williams, Billy M},
  journal={Transportation Research Record},
  volume={1776},
  number={1},
  pages={194--200},
  year={2001},
  publisher={SAGE Publications Sage CA: Los Angeles, CA}
}


@online{emoticonwiki,
  title={List of emoticons},
  url={https://en.wikipedia.org/wiki/List_of_emoticons},
  urldate = {2021-09-28}, 
  publisher={Wikimedia Foundation, Inc.}
}


@online{emojipack,
  title={Emoji for Python},
  url={https://pypi.org/project/emoji/},
  urldate = {2021-09-28}, 
  publisher={Taehoon Kim}
}


@inproceedings{emoji1,
  title={Exploiting emoticons in sentiment analysis},
  author={Hogenboom, Alexander and Bal, Daniella and Frasincar, Flavius and Bal, Malissa and de Jong, Franciska and Kaymak, Uzay},
  booktitle={Proceedings of the 28th annual ACM symposium on applied computing},
  pages={703--710},
  year={2013}
}

@INPROCEEDINGS{emoji2,
  author={Boia, Marina and Faltings, Boi and Musat, Claudiu-Cristian and Pu, Pearl},
  booktitle={2013 International Conference on Social Computing}, 
  title={A :) Is Worth a Thousand Words: How People Attach Sentiment to Emoticons and Words in Tweets}, 
  year={2013},
  volume={},
  number={},
  pages={345-350},
  doi={10.1109/SocialCom.2013.54}}


@inproceedings{stopwords1,
    title = "On Stopwords, Filtering and Data Sparsity for Sentiment Analysis of {T}witter",
    author = "Saif, Hassan  and
      Fernandez, Miriam  and
      He, Yulan  and
      Alani, Harith",
    booktitle = "Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)",
    month = may,
    year = "2014",
    address = "Reykjavik, Iceland",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2014/pdf/292_Paper.pdf",
    pages = "810--817",
    abstract = "Sentiment classification over Twitter is usually affected by the noisy nature (abbreviations, irregular forms) of tweets data. A popular procedure to reduce the noise of textual data is to remove stopwords by using pre-compiled stopword lists or more sophisticated methods for dynamic stopword identification. However, the effectiveness of removing stopwords in the context of Twitter sentiment classification has been debated in the last few years. In this paper we investigate whether removing stopwords helps or hampers the effectiveness of Twitter sentiment classification methods. To this end, we apply six different stopword identification methods to Twitter data from six different datasets and observe how removing stopwords affects two well-known supervised sentiment classification methods. We assess the impact of removing stopwords by observing fluctuations on the level of data sparsity, the size of the classifier{'}s feature space and its classification performance. Our results show that using pre-compiled lists of stopwords negatively impacts the performance of Twitter sentiment classification approaches. On the other hand, the dynamic generation of stopword lists, by removing those infrequent terms appearing only once in the corpus, appears to be the optimal method to maintaining a high classification performance while reducing the data sparsity and shrinking the feature space.",
}




@article{var1,
  title={Does the stock market in India move with Asia?: A multivariate cointegration-vector autoregression approach},
  author={Mukherjee, Paramita and Bose, Suchismita},
  journal={Emerging Markets Finance and Trade},
  volume={44},
  number={5},
  pages={5--22},
  year={2008},
  publisher={Taylor \& Francis}
}


@article{var2,
  title={Co-movements of major European community stock markets: A vector autoregression analysis},
  author={Friedman, Joseph and Shachmurove, Yochanan},
  journal={Global finance journal},
  volume={8},
  number={2},
  pages={257--277},
  year={1997},
  publisher={North-Holland}
}

@inproceedings{textclass1,
  title={Recurrent convolutional neural networks for text classification},
  author={Lai, Siwei and Xu, Liheng and Liu, Kang and Zhao, Jun},
  booktitle={Twenty-ninth AAAI conference on artificial intelligence},
  year={2015}
}


@inproceedings{sum1,
  title={Nlp based latent semantic analysis for legal text summarization},
  author={Merchant, Kaiz and Pande, Yash},
  booktitle={2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI)},
  pages={1803--1807},
  year={2018},
  organization={IEEE}
}


@article{qas1,
  title={MEANS: A medical question-answering system combining NLP techniques and semantic Web technologies},
  author={Abacha, Asma Ben and Zweigenbaum, Pierre},
  journal={Information processing \& management},
  volume={51},
  number={5},
  pages={570--594},
  year={2015},
  publisher={Elsevier}
}

@book{asr1,
  title={Automatic Speech Recognition.},
  author={Yu, Dong and Deng, Li},
  year={2016},
  publisher={Springer}
}


@inproceedings{mt1,
  title={On application of natural language processing in machine translation},
  author={Zong, Zhaorong and Hong, Changchun},
  booktitle={2018 3rd International Conference on Mechanical, Control and Computer Engineering (ICMCCE)},
  pages={506--510},
  year={2018},
  organization={IEEE}
}


@article{prep3,
  title={Comparison research on text pre-processing methods on twitter sentiment analysis},
  author={Jianqiang, Zhao and Xiaolin, Gui},
  journal={IEEE Access},
  volume={5},
  pages={2870--2879},
  year={2017},
  publisher={IEEE}
}


@inproceedings{prep2,
  title={A Comparison between Preprocessing Techniques for Sentiment Analysis in Twitter.},
  author={Angiani, Giulio and Ferrari, Laura and Fontanini, Tomaso and Fornacciari, Paolo and Iotti, Eleonora and Magliani, Federico and Manicardi, Stefano},
  booktitle={KDWeb},
  year={2016}
}



@article{topmoda1,
  title={Latent Dirichlet allocation (LDA) and topic modeling: models, applications, a survey},
  author={Jelodar, Hamed and Wang, Yongli and Yuan, Chi and Feng, Xia and Jiang, Xiahui and Li, Yanchao and Zhao, Liang},
  journal={Multimedia Tools and Applications},
  volume={78},
  number={11},
  pages={15169--15211},
  year={2019},
  publisher={Springer}
}



@article{prep1,
  title={A comparative evaluation of pre-processing techniques and their interactions for twitter sentiment analysis},
  author={Symeonidis, Symeon and Effrosynidis, Dimitrios and Arampatzis, Avi},
  journal={Expert Systems with Applications},
  volume={110},
  pages={298--310},
  year={2018},
  publisher={Elsevier}
}


@inproceedings{stock6,
  title={Sentiment analysis of Twitter data for predicting stock market movements},
  author={Pagolu, Venkata Sasank and Reddy, Kamal Nayan and Panda, Ganapati and Majhi, Babita},
  booktitle={2016 international conference on signal processing, communication, power and embedded system (SCOPES)},
  pages={1345--1350},
  year={2016},
  organization={IEEE}
}




@inproceedings{stock5,
  title={Topic modeling based sentiment analysis on social media for stock market prediction},
  author={Nguyen, Thien Hai and Shirai, Kiyoaki},
  booktitle={Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={1354--1364},
  year={2015}
}


@article{stock4,
  title={Using twitter to predict the stock market},
  author={Nofer, Michael and Hinz, Oliver},
  journal={Business \& Information Systems Engineering},
  volume={57},
  number={4},
  pages={229--242},
  year={2015},
  publisher={Springer}
}

@article{stock3,
  title={Twitter mood predicts the stock market},
  author={Bollen, Johan and Mao, Huina and Zeng, Xiaojun},
  journal={Journal of computational science},
  volume={2},
  number={1},
  pages={1--8},
  year={2011},
  publisher={Elsevier}
}



@article{stock2,
  title={Stock market prediction with multiple classifiers},
  author={Qian, Bo and Rasheed, Khaled},
  journal={Applied Intelligence},
  volume={26},
  number={1},
  pages={25--33},
  year={2007},
  publisher={Springer}
}





@article{stock1,
  title={The behavior of stock-market prices},
  author={Fama, Eugene F},
  journal={The journal of Business},
  volume={38},
  number={1},
  pages={34--105},
  year={1965},
  publisher={JSTOR}
}


 @INPROCEEDINGS{twitsent1,
  author={Wagh, Rasika and Punde, Payal},
  booktitle={2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA)}, 
  title={Survey on Sentiment Analysis using Twitter Dataset}, 
  year={2018},
  volume={},
  number={},
  pages={208-211},
  doi={10.1109/ICECA.2018.8474783}}


@misc{twituse, title={Twitter: Monthly active users worldwide}, url={https://www.statista.com/statistics/282087/number-of-monthly-active-twitter-users/}, journal={Statista}, author={Published by                                    Statista Research Department}, year={2021}, month={Jan}} 


@inproceedings{toptweet1,
  title={Empirical study of topic modeling in twitter},
  author={Hong, Liangjie and Davison, Brian D},
  booktitle={Proceedings of the first workshop on social media analytics},
  pages={80--88},
  year={2010}
}


@inproceedings{toptweet3,
  title={Topic modeling in twitter: Aggregating tweets by conversations},
  author={Alvarez-Melis, David and Saveski, Martin},
  booktitle={Tenth international AAAI conference on web and social media},
  year={2016}
}


@inproceedings{toptweet2,
  title={Large-scale high-precision topic modeling on twitter},
  author={Yang, Shuang-Hong and Kolcz, Alek and Schlaikjer, Andy and Gupta, Pankaj},
  booktitle={Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={1907--1916},
  year={2014}
}

@inproceedings{topmod3,
  title={Joint sentiment/topic model for sentiment analysis},
  author={Lin, Chenghua and He, Yulan},
  booktitle={Proceedings of the 18th ACM conference on Information and knowledge management},
  pages={375--384},
  year={2009}
}


@article{topmod2,
  title={Topic modeling and sentiment analysis of online review for airlines},
  author={Kwon, Hye-Jin and Ban, Hyun-Jeong and Jun, Jae-Kyoon and Kim, Hak-Seon},
  journal={Information},
  volume={12},
  number={2},
  pages={78},
  year={2021},
  publisher={Multidisciplinary Digital Publishing Institute}
}
@inproceedings{topmod1,
  title={Joint sentiment/topic model for sentiment analysis},
  author={Lin, Chenghua and He, Yulan},
  booktitle={Proceedings of the 18th ACM conference on Information and knowledge management},
  pages={375--384},
  year={2009}
}

@inproceedings{slm1,
  title={Methods for sentiment analysis of Twitter messages},
  author={Barhan, Anton and Shakhomirov, Andrey},
  booktitle={12th Conference of FRUCT Association},
  pages={215--222},
  year={2012}
}

@inproceedings{hybrid1,
  title={NILC\_USP: A hybrid system for sentiment analysis in twitter messages},
  author={Balage Filho, Pedro and Pardo, Thiago},
  booktitle={Second Joint Conference on Lexical and Computational Semantics (* SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013)},
  pages={568--572},
  year={2013}
}


@inproceedings{unsuper1,
  title={Unsupervised sentiment analysis with emotional signals},
  author={Hu, Xia and Tang, Jiliang and Gao, Huiji and Liu, Huan},
  booktitle={Proceedings of the 22nd international conference on World Wide Web},
  pages={607--618},
  year={2013}
}



@inproceedings{lex1,
  title={A real-time Twitter sentiment analysis using an unsupervised method},
  author={Azzouza, Noureddine and Akli-Astouati, Karima and Oussalah, Amira and Bachir, Samy Ait},
  booktitle={Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics},
  pages={1--10},
  year={2017}
}


@article{ens1,
  title={Ensemble of feature sets and classification algorithms for sentiment classification},
  author={Xia, Rui and Zong, Chengqing and Li, Shoushan},
  journal={Information sciences},
  volume={181},
  number={6},
  pages={1138--1152},
  year={2011},
  publisher={Elsevier}
}


@inproceedings{svm1,
  title={Sentiment analysis using support vector machine},
  author={Zainuddin, Nurulhuda and Selamat, Ali},
  booktitle={2014 international conference on computer, communications, and control technology (I4CT)},
  pages={333--337},
  year={2014},
  organization={IEEE}
}

@article{nb1,
  title={Sentiment analysis of review datasets using naive bayes and k-nn classifier},
  author={Dey, Lopamudra and Chakraborty, Sanjay and Biswas, Anuraag and Bose, Beepa and Tiwari, Sweta},
  journal={arXiv preprint arXiv:1610.09982},
  year={2016}
}


@inproceedings{bots,
  title={Using sentiment to detect bots on twitter: Are humans more opinionated than bots?},
  author={Dickerson, John P and Kagan, Vadim and Subrahmanian, VS},
  booktitle={2014 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2014)},
  pages={620--627},
  year={2014},
  organization={IEEE}
}


@inproceedings{lowercase,
  title={A comparison of pre-processing techniques for twitter sentiment analysis},
  author={Effrosynidis, Dimitrios and Symeonidis, Symeon and Arampatzis, Avi},
  booktitle={International Conference on Theory and Practice of Digital Libraries},
  pages={394--406},
  year={2017},
  organization={Springer}
}


@article{me1,
  title={An improved algorithm for sentiment analysis based on maximum entropy},
  author={Xie, Xin and Ge, Songlin and Hu, Fengping and Xie, Mingye and Jiang, Nan},
  journal={Soft Computing},
  volume={23},
  number={2},
  pages={599--611},
  year={2019},
  publisher={Springer}
}

@article{sa3,
  title={A study on sentiment analysis techniques of Twitter data},
  author={Alsaeedi, Abdullah and Khan, Mohammad Zubair}
}


@INPROCEEDINGS{sa2,  author={Haque, Tanjim Ul and Saber, Nudrat Nawal and Shah, Faisal Muhammad},  booktitle={2018 IEEE International Conference on Innovative Research and Development (ICIRD)},   title={Sentiment analysis on large scale Amazon product reviews},   year={2018},  volume={},  number={},  pages={1-6},  doi={10.1109/ICIRD.2018.8376299}}



@INPROCEEDINGS{sa1,
  author={Singh, V. K. and Piryani, R. and Uddin, A. and Waila, P.},
  booktitle={2013 International Mutli-Conference on Automation, Computing, Communication, Control and Compressed Sensing (iMac4s)}, 
  title={Sentiment analysis of movie reviews: A new feature-based heuristic for aspect-level sentiment classification}, 
  year={2013},
  volume={},
  number={},
  pages={712-717},
  doi={10.1109/iMac4s.2013.6526500}}






@article{blei,
author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
title = {Latent Dirichlet Allocation},
year = {2003},
issue_date = {3/1/2003},
publisher = {JMLR.org},
volume = {3},
number = {null},
issn = {1532-4435},
abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for
collections of discrete data such as text corpora. LDA is a three-level hierarchical
Bayesian model, in which each item of a collection is modeled as a finite mixture
over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture
over an underlying set of topic probabilities. In the context of text modeling, the
topic probabilities provide an explicit representation of a document. We present efficient
approximate inference techniques based on variational methods and an EM algorithm
for empirical Bayes parameter estimation. We report results in document modeling,
text classification, and collaborative filtering, comparing to a mixture of unigrams
model and the probabilistic LSI model.},
journal = {J. Mach. Learn. Res.},
month = mar,
pages = {993–1022},
numpages = {30}
}


@article{nmf3,
title = {Experimental explorations on short text topic mining between LDA and NMF based Schemes},
journal = {Knowledge-Based Systems},
volume = {163},
pages = {1-13},
year = {2019},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2018.08.011},
url = {https://www.sciencedirect.com/science/article/pii/S0950705118304076},
author = {Yong Chen and Hui Zhang and Rui Liu and Zhiwen Ye and Jianying Lin},
keywords = {Short text mining, Topic modeling, Latent dirichlet allocation (LDA), Non-negative matrix factorization (NMF), Knowledge-based learning},
abstract = {Learning topics from short texts has become a critical and fundamental task for understanding the widely-spread streaming social messages, e.g., tweets, snippets and questions/answers. Up to date, there are two distinctive topic learning schemes: generative probabilistic graphical models and geometrically linear algebra approaches, with LDA and NMF being the representative works, respectively. Since these two methods both could uncover the latent topics hidden in the unstructured short texts, some interesting doubts are coming to our minds that which one is better and why? Are there any other more effective extensions? In order to explore valuable insights between LDA and NMF based learning schemes, we comprehensively conduct a series of experiments into two parts. Specifically, the basic LDA and NMF are compared with different experimental settings on several public short text datasets in the first part which would exhibit that NMF tends to perform better than LDA; in the second part, we propose a novel model called “Knowledge-guided Non-negative Matrix Factorization for Better Short Text Topic Mining” (abbreviated as KGNMF), which leverages external knowledge as a semantic regulator with low-rank formalizations, yielding up a time-efficient algorithm. Extensive experiments are conducted on three representative corpora with currently typical short text topic models to demonstrate the effectiveness of our proposed KGNMF. Overall, learning with NMF-based schemes is another effective manner in short text topic mining in addition to the popular LDA-based paradigms.}
}

@book{nltk,
  title={Natural language processing with Python: analyzing text with the natural language toolkit},
  author={Bird, Steven and Klein, Ewan and Loper, Edward},
  year={2009},
  publisher={" O'Reilly Media, Inc."}
}

@inproceedings{bischof,
  title={Summarizing topical content with word frequency and exclusivity},
  author={Bischof, Jonathan and Airoldi, Edoardo M},
  booktitle={Proceedings of the 29th International Conference on Machine Learning (ICML-12)},
  pages={201--208},
  year={2012}
}

@inproceedings{nmf2,
author = {Stevens, Keith and Kegelmeyer, Philip and Andrzejewski, David and Buttler, David},
title = {Exploring Topic Coherence over Many Models and Many Topics},
year = {2012},
publisher = {Association for Computational Linguistics},
address = {USA},
abstract = {We apply two new automated semantic evaluations to three distinct latent topic models.
Both metrics have been shown to align with human evaluations and provide a balance
between internal measures of information gain and comparisons to human ratings of
coherent topics. We improve upon the measures by introducing new aggregate measures
that allows for comparing complete topic models. We further compare the automated
measures to other metrics for topic models, comparison to manually crafted semantic
tests and document classification. Our experiments reveal that LDA and LSA each have
different strengths; LDA best learns descriptive topics while LSA is best at creating
a compact semantic representation of documents and words in a corpus.},
booktitle = {Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning},
pages = {952–961},
numpages = {10},
location = {Jeju Island, Korea},
series = {EMNLP-CoNLL '12}
}




@online{diriex,
  author = {{Sue Liu}},
  title = {Dirichlet distribution},
  year = 2019,
  url = {https://towardsdatascience.com/dirichlet-distribution-a82ab942a879},
  urldate = {2019-01-06}
}

@unpublished{mallet,
   author = "Andrew Kachites McCallum",
    title = "MALLET: A Machine Learning for Language Toolkit",
    note = "http://mallet.cs.umass.edu",
    year = 2002}


@book{albrecht, place={Cambridge}, title={Blueprints for text analytics using python: Machine learning-based solutions for common real world (nlp) applications}, publisher={O'Reilly}, author={Albrecht, Jens and Ramachandran, Sidharth and Winkler, Christian}, year={2020}} 

@incollection{steyvers,
  title={Probabilistic topic models},
  author={Steyvers, Mark and Griffiths, Tom},
  booktitle={Handbook of latent semantic analysis},
  pages={439--460},
  year={2007},
  publisher={Psychology Press}
}


@online{dragonfly,
  author = {{Christof Schöch}},
  title = {Topic Modeling with MALLET: Hyperparameter Optimization},
  year = 2016,
  url = {https://dragonfly.hypotheses.org/1051},
  urldate = {2016-11-14}
}


@inproceedings{ldavis,
author = {Sievert, Carson and Shirley, Kenneth},
year = {2014},
month = {06},
pages = {},
title = {LDAvis: A method for visualizing and interpreting topics},
doi = {10.13140/2.1.1394.3043}
}


@Manual{bokeh,
title = {Bokeh: Python library for interactive visualization},
author = {{Bokeh Development Team}},
year = {2018},
url = {https://bokeh.pydata.org/en/latest/},
}


@article{chaung,
author = {Chuang, Jason and Manning, Christopher and Heer, Jeffrey},
year = {2012},
month = {05},
pages = {},
title = {Termite: Visualization Techniques for Assessing Textual Topic Models},
doi = {10.1145/2254556.2254572}
}




@inproceedings{cohermes,
author = {R\"{o}der, Michael and Both, Andreas and Hinneburg, Alexander},
title = {Exploring the Space of Topic Coherence Measures},
year = {2015},
isbn = {9781450333177},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2684822.2685324},
doi = {10.1145/2684822.2685324},
abstract = {Quantifying the coherence of a set of statements is a long standing problem with many
potential applications that has attracted researchers from different sciences. The
special case of measuring coherence of topics has been recently studied to remedy
the problem that topic models give no guaranty on the interpretablity of their output.
Several benchmark datasets were produced that record human judgements of the interpretability
of topics. We are the first to propose a framework that allows to construct existing
word based coherence measures as well as new ones by combining elementary components.
We conduct a systematic search of the space of coherence measures using all publicly
available topic relevance data for the evaluation. Our results show that new combinations
of components outperform existing measures with respect to correlation to human ratings.
nFinally, we outline how our results can be transferred to further applications in
the context of text mining, information retrieval and the world wide web.},
booktitle = {Proceedings of the Eighth ACM International Conference on Web Search and Data Mining},
pages = {399–408},
numpages = {10},
keywords = {topic model, topic evaluation, topic coherence},
location = {Shanghai, China},
series = {WSDM '15}
}





@article{rehurek2011gensim,
  title={Gensim--python framework for vector space modelling},
  author={Rehurek, Radim and Sojka, Petr},
  journal={NLP Centre, Faculty of Informatics, Masaryk University, Brno, Czech Republic},
  volume={3},
  number={2},
  year={2011}
}


@misc{twit1,
  title = {{Twitter Usage Statistics} Internet Live Stats},
  howpublished = {\url{https://www.internetlivestats.com/twitter-statistics/}},
  note = {Accessed: 2021-09-16}
}


@online{twit2,
  author = {{Internet Live Stats}},
  title = {Twitter Usage Statistics},
  year = 2021,
  url = {https://www.internetlivestats.com/twitter-statistics/},
  urldate = {2021-09-16}
}




@article{einstein,
    author =       "Albert Einstein",
    title =        "{Zur Elektrodynamik bewegter K{\"o}rper}. ({German})
        [{On} the electrodynamics of moving bodies]",
    journal =      "Annalen der Physik",
    volume =       "322",
    number =       "10",
    pages =        "891--921",
    year =         "1905",
    DOI =          "http://dx.doi.org/10.1002/andp.19053221004"
}

@book{latexcompanion,
    author    = "Michel Goossens and Frank Mittelbach and Alexander Samarin",
    title     = "The \LaTeX\ Companion",
    year      = "1993",
    publisher = "Addison-Wesley",
    address   = "Reading, Massachusetts"
}

@misc{knuthwebsite,
    author    = "Donald Knuth",
    title     = "Knuth: Computers and Typesetting",
    url       = "http://www-cs-faculty.stanford.edu/\~{}uno/abcde.html"
}